{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Implementation of RBF neural network\n",
    "In this section you should implement a RBF neural network that can be use as classifier. for do this you should fill missing part. just find optimalbeta and write RBF training algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data MNIST\n",
    "In this section we use a real dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (5000, 62)\n",
      "Train labels shape:  (5000,)\n",
      "Test data shape:  (2500, 62)\n",
      "Test labels shape:  (2500,)\n"
     ]
    }
   ],
   "source": [
    "import random as rnd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "import math\n",
    "\n",
    "\n",
    "from TinyMNIST_loader import * #from dataloader import select_features\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread\n",
    "'''\n",
    "val_num = 1000\n",
    "train_num = 49000\n",
    "test_num = 10000\n",
    "\n",
    "train_data, train_labels, test_data, test_labels,\\\n",
    "    class_names, n_train, n_test, n_class, n_features = select_features()\n",
    "'''\n",
    "X_train = train_data\n",
    "y_train = train_labels\n",
    "X_test = test_data\n",
    "y_test = test_labels\n",
    "# Subsample the data\n",
    "#df_train = X_train\n",
    "#df_test = X_test\n",
    "trueLabels = np.concatenate((y_train,y_test),axis=0)\n",
    "print ('Train data shape: ', X_train.shape)\n",
    "print ('Train labels shape: ', y_train.shape)\n",
    "print ('Test data shape: ', X_test.shape)\n",
    "print ('Test labels shape: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main\n",
    "Tune parameters, Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta 0.01 mean_cv_accuracy 77.460000\n",
      "beta 0.49 mean_cv_accuracy 78.540000\n",
      "beta 1 mean_cv_accuracy 78.820000\n",
      "beta 2 mean_cv_accuracy 77.580000\n",
      "beta 3 mean_cv_accuracy 76.580000\n",
      "beta 4 mean_cv_accuracy 71.300000\n",
      "beta 9 mean_cv_accuracy 55.140000\n",
      "beta 25 mean_cv_accuracy 29.180000\n",
      "beta 49 mean_cv_accuracy 20.860000\n",
      "beta 81 mean_cv_accuracy 13.760000\n",
      "optimal beta:  1\n",
      "Optimal Accuracy 78.82\n",
      "---------\n",
      "training...\n",
      "testing...\n",
      "Percent accuracy on test data: 70.39999999999999\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    t=RBFNet()\n",
    "    nlabels=10                #total number of labels\n",
    "    nclusters=50              #number of clusters for k-means\n",
    "    ksplits=10                #ksplits-fold cross validation\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    #X_train = train_data[:1000,:]\n",
    "    #y_train = train_labels[:1000]\n",
    "\n",
    "  \n",
    "    #############################################################################\n",
    "    ###   Calculate optimal beta for this network and put it in to optimalBeta  \n",
    "    ###                              with crossvalidatin                        \n",
    "    #############################################################################\n",
    "    optimalBeta =None\n",
    "    \n",
    "    betas = [0.01, 0.49, 1, 2, 3, 4, 9, 25, 49, 81]\n",
    "    N = X_train.shape[0]\n",
    "    Fold_size = math.floor(N / ksplits)\n",
    "    mean_cv_accuracy = np.zeros(len(betas))\n",
    "    b_index = -1\n",
    "\n",
    "    for beta in betas:\n",
    "        b_index += 1\n",
    "        #accuracy[i]=t.kFoldValidation(validationData,ksplits,nlabels,nclusters,beta)\n",
    "        accuracy = np.zeros(ksplits)\n",
    "        #def kFoldValidation(self,data,k,nlabels,nclusters,beta):\n",
    "        # k_fold_cv\n",
    "        from sklearn.model_selection import KFold\n",
    "        kf = KFold(n_splits = ksplits)\n",
    "        cv_index = -1\n",
    "        for train_index, test_index in kf.split(X_train):\n",
    "            #print('TRAIN:', train_index, 'TEST:', test_index)\n",
    "            X_training_fold, X_testing_fold = X_train[train_index], X_train[test_index]\n",
    "            y_training_fold, y_testing_fold = y_train[train_index], y_train[test_index]\n",
    "            #print(y_train.shape)\n",
    "            predicted_y_training_fold, centers, centroidLabel = \\\n",
    "                        t.trainRBF(X_training_fold, y_training_fold,nclusters,beta,nlabels, y_training_fold)\n",
    "            predicted_y_testing_fold = \\\n",
    "                        t.RBF(X_testing_fold, y_testing_fold,beta, centers, centroidLabel, nlabels)\n",
    "            \n",
    "            accuracy = np.sum(y_testing_fold == predicted_y_testing_fold)/len(y_testing_fold)\n",
    "            mean_cv_accuracy[b_index] += accuracy * 100\n",
    "            \n",
    "        mean_cv_accuracy[b_index] = mean_cv_accuracy[b_index] / ksplits\n",
    "        print('beta %g mean_cv_accuracy %f' %(beta, mean_cv_accuracy[b_index]))\n",
    "        \n",
    "    optimalBeta = betas[np.argmax(mean_cv_accuracy)]\n",
    "    print('optimal beta: ', optimalBeta)\n",
    "    optimalAccuracy = np.max(mean_cv_accuracy)\n",
    "    print('Optimal Accuracy',optimalAccuracy)\n",
    "    print('---------')\n",
    "    #############################################################################\n",
    "    #                              END OF YOUR CODE                             #\n",
    "    #############################################################################\n",
    "    #Train\n",
    "    print('training...')\n",
    "    (predictedLabels_train,centers_train,centroidLabel_train) = \\\n",
    "                        t.trainRBF(X_train, y_train, nclusters, optimalBeta, nlabels, y_train)\n",
    "\n",
    "    #Test\n",
    "    print('testing...')\n",
    "    predictedTestLabels = \\\n",
    "                        t.RBF(X_test, y_test, optimalBeta, centers_train, centroidLabel_train, nlabels)\n",
    "\n",
    "    #Test accuracy\n",
    "    testLabels=y_test\n",
    "    accuracy=0\n",
    "    for y in range(len(predictedTestLabels)):\n",
    "        if predictedTestLabels[y] == testLabels[y]:\n",
    "            accuracy+=1\n",
    "    accuracy=(accuracy/len(predictedTestLabels))*100\n",
    "    print('Percent accuracy on test data:',accuracy)\n",
    "\n",
    "\n",
    "class RBFNet():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def calcKmean(self,X,n): #data -> X\n",
    "        kmeanz = KMeans(n_clusters=n).fit(X)\n",
    "        centers=np.array(kmeanz.cluster_centers_)\n",
    "        #print('pairwise_distances_argmin_min... ')\n",
    "        closest,_=pairwise_distances_argmin_min(kmeanz.cluster_centers_,X)\n",
    "        closest=np.array(closest)\n",
    "        return (centers,closest)\n",
    "\n",
    "    def RBF(self,X, y, beta, centers, centroidLabels, nlabels): #data -> X, y\n",
    "        #############################################################################\n",
    "        ### Train RBF to produce predicted labels                                   \n",
    "        ### you should return predictedlabels as shape of (N,)                        \n",
    "        #############################################################################\n",
    "        \n",
    "        centroid_scores = np.zeros((len(centers), X.shape[0]))\n",
    "        for c in range(len(centers)):\n",
    "            for sample_i in range(X.shape[0]):\n",
    "                #print(np.squeeze(beta))\n",
    "                centroid_scores[c, sample_i]= np.exp((-1./beta) * np.square(np.linalg.norm(np.subtract(X[sample_i],centers[c]))))\n",
    "\n",
    "        Label_scores = np.zeros((nlabels, X.shape[0]))\n",
    "        for c in range(len(centroidLabels)):\n",
    "            for sample_i in range(X.shape[0]):\n",
    "                #print(centroidLabels[c])\n",
    "                #print(centroid_scores[c, sample_i])\n",
    "                Label_scores[int(centroidLabels[c]), sample_i] += centroid_scores[c, sample_i]\n",
    "        predictedLabels = np.argmax(Label_scores, axis = 0)\n",
    "        #print(predictedLabels)\n",
    "        #############################################################################\n",
    "        #                              END OF YOUR CODE                             #\n",
    "        #############################################################################\n",
    "\n",
    "        return predictedLabels\n",
    "\n",
    "    def trainRBF(self,X, y, k, beta, nlabels, trueLabels): #data -> X,y\n",
    "        #k-means: Getting centroids and the row indices (in df_train) of the data points closest to the centroids\n",
    "        t=RBFNet()\n",
    "        #print('training started!')\n",
    "        (centers,indices)=t.calcKmean(X,k)\n",
    "        #The label of each centroid according training data\n",
    "        #print('finished Kmeans!')\n",
    "        centroidLabel=np.zeros(len(centers))\n",
    "        for x in range(len(centers)):\n",
    "            #print(y.shape)\n",
    "            centroidLabel[x]=trueLabels[indices[x]]#trueLabels[indices[x]]\n",
    "        #print('trained!')\n",
    "        predictedLabels=t.RBF(X, y,beta,centers,centroidLabel,nlabels)\n",
    "        return (predictedLabels,centers,centroidLabel)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
